{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/jeong/Desktop/baf/foremotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"index\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeong\\BAF-24-2-medical\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeong\\BAF-24-2-medical\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True  # 크기 불일치 무시\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1340, 5024, 6680, 3997, 6569, 2959, 373, 1362, 2401, 749, 5520, 5733, 7204, 6, 4109, 5756, 5842, 3957, 2755, 3774, 5847, 2580, 3483, 4103, 5479, 2764, 4944, 6074, 43, 2588, 7482, 5413, 1356, 6589, 3324, 4457, 7422, 5216, 1310, 3967, 4921, 4892, 1360, 2415, 2622, 4535, 3649, 1832, 674, 5330]\n"
     ]
    }
   ],
   "source": [
    "random.seed(427)\n",
    "random_number = random.sample(range(0,(len(df)-1)), 50)\n",
    "print(random_number)\n",
    "df_ex = df.iloc[random_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = df_ex['ReviewText'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "힘이 넘쳐요\n",
      "한달먹어보고 말했다\n",
      "이제 일주일째 먹고있어요글쎄요 효능이 있다고 생각하고먹고있어요그래야 효능이 있으니까요\n",
      "잘 먹고 있어요\n",
      "싸게 잘 구매 했습니다다 먹으면 재구매 할께요\n",
      "먹고나니 좋은것 같습니다\n",
      "잘먹고 있어요\n",
      "먹었는데 효과가 상당히 좋습니다 그리고 가격적으로 좀 너무 싸서 의심했는데 이거는 가성비가 너무 좋습니다 사서 드시고 건강 챙겨오세요\n",
      "살짝 약냄새가 나요 하시만 먹는데는 큰지장 없어요\n",
      "새콤달콤 맛있어요\n",
      "지속적으로 복용하고 있습니다 감사합니다\n",
      "싸고 좋은것 같아 먹어보고 효과는 나중에\n",
      "재구매합니다\n",
      "좋은 가격에 잘 받았습니다\n",
      "좋은 상품을 많이 파세요재구매 합니다\n",
      "두번째 구매했습니다 변비가 심한편인데 요즘규칙적으로 하루 한번씩 볼일을 보는 것 같아요속이 편하고 좋아요\n",
      "딸아이가 다리가 너무 저리다고 해서 구입했어요 효과있다고 합니다 먹을때와 먹지 않을 때 다르다고 하네요 꾸준히 먹을게요\n",
      "좋아요 좋아요 좋아요\n",
      "캡슐이 은박지에 들어있어외출시 나누어 휴대하기 좋네요건강기능 식품으로 점차 신뢰가됩니다\n",
      "먹어보니 괜찮아서 더 구매할려구요\n",
      "좋은 상품 구매해서 좋았고 복용을 해 보니 피로감이 많이감소한것 같습니다 만족합니다 감사합니다\n",
      "믿을 수 있고 가격도 좋아요\n",
      "한알먹어보니 소변에서 별반응이없네요 비맥스 섭취하면 노란색이 학연하게 나타나던데 메가씨비타민씨 더먹어볼게요 하나먹어보고 효능이런걸 논한다는게 \n",
      "구매후기는 복용후 다시 자세히 작성하겠습니다\n",
      "바타민 메트르비와 부스터와 같이 복용 중인데 피로가 덜하고 힘이 생기는거 같아 먹고 잇어요\n",
      "잘 받았습니다\n",
      "갱년기 울 와이프 체육관 다니며 운동하고 다이어트 한다길래주문했어요 효과있기를\n",
      "운동하는데 쥐나는거 예방도 하구요\n",
      "저렴한 가격으로 열심히 먹고 있습니다 추후 혈당상태를 다시 남기도록 할게요\n",
      "싸게 사서 좋아요많이 파세요\n",
      "매우 흡족합니다\n",
      "효과 아주 바로 느껴집니다좋은 제품 저렴한 가격으로 구매했습니다감사합니다\n",
      "잘 먹고 있어요 한 2주 복용했는데 아직은 잘 모르겠어요 조금 더 먹어 봐야 알겠죠\n",
      "부모님이 좋은것 같다고 하셔서 재구매합니다 \n",
      "새주소로 변경했는데 여전히 예전 주소로 배달이 되네요 이대로는 주문할 수가 없어요 어케 해야하나요 정보수정을 다 했는데\n",
      "좋은제품 감사합니다\n",
      "이제시작했는데먹기도좋고간편하고실용적인데효과가있는것갔네요꾸준히먹고또나중에후기남기겠읍니다\n",
      "약국에서 권해서 먹던 건데여기가 더 저렴해서 구매했어요식사도 불규칙하고에어컨 틀어도 더운 곳에서 일하다보니저에게는 필수네요많이 파시고 번창하세요\n",
      "2통째 먹고 있어요작아서 더 먹기 좋아요\n",
      "좋은 제품 빠른 배송 너무 감사드립니다\n",
      "배송도 빠르고 너무 좋습니다\n",
      "면역에 좋다고해서 복용해보지만 아직잘 모르겠고 추가주문해서 장복할려고 합니다\n",
      "힘이생기는것 같은데 아직은 잘모르겠어요좋겠죠\n",
      "빠른배송개봉 후 냄새가 좀 나지만 먹을만 했음작은알이어서 먹기는 편함\n",
      "배송도 빠르게 해주시고 내용물도 만족스럽습니다\n",
      "착한가격에 구매해서 복용중인데 몇일밖에 안되서 아직은 잘 모르겠지만 아연이 좋다고하니 잘 복용하겠습니다\n",
      "잘 복용하고 있습니다\n",
      "아르기닌 참 좋은데 아르기닌 정말 좋은데 어떻게 표현할 방법이 없네\n",
      "잘 먹어보겠습니다 크기도 적당하고 목넘김 좋고뚜껑도 안전캡네요잘 먹고 건강해져 보겠습니다계속 재구매 예정입니다\n",
      "가성비 최고 만족합니다\n"
     ]
    }
   ],
   "source": [
    "clean = []\n",
    "for i in range(0,len(list)):\n",
    "    if(list[i] != numpy.nan):\n",
    "        print(list[i])\n",
    "        clean.append(list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 힘이 넘쳐요\n",
      "Sentiment: LABEL_0, Score: 0.58\n",
      "\n",
      "Text: 한달먹어보고 말했다\n",
      "Sentiment: LABEL_1, Score: 0.55\n",
      "\n",
      "Text: 이제 일주일째 먹고있어요글쎄요 효능이 있다고 생각하고먹고있어요그래야 효능이 있으니까요\n",
      "Sentiment: LABEL_1, Score: 0.60\n",
      "\n",
      "Text: 잘 먹고 있어요\n",
      "Sentiment: LABEL_0, Score: 0.64\n",
      "\n",
      "Text: 싸게 잘 구매 했습니다다 먹으면 재구매 할께요\n",
      "Sentiment: LABEL_0, Score: 0.57\n",
      "\n",
      "Text: 먹고나니 좋은것 같습니다\n",
      "Sentiment: LABEL_1, Score: 0.54\n",
      "\n",
      "Text: 잘먹고 있어요\n",
      "Sentiment: LABEL_1, Score: 0.58\n",
      "\n",
      "Text: 먹었는데 효과가 상당히 좋습니다 그리고 가격적으로 좀 너무 싸서 의심했는데 이거는 가성비가 너무 좋습니다 사서 드시고 건강 챙겨오세요\n",
      "Sentiment: LABEL_1, Score: 0.53\n",
      "\n",
      "Text: 살짝 약냄새가 나요 하시만 먹는데는 큰지장 없어요\n",
      "Sentiment: LABEL_1, Score: 0.59\n",
      "\n",
      "Text: 새콤달콤 맛있어요\n",
      "Sentiment: LABEL_1, Score: 0.50\n",
      "\n",
      "Text: 지속적으로 복용하고 있습니다 감사합니다\n",
      "Sentiment: LABEL_0, Score: 0.51\n",
      "\n",
      "Text: 싸고 좋은것 같아 먹어보고 효과는 나중에\n",
      "Sentiment: LABEL_0, Score: 0.59\n",
      "\n",
      "Text: 재구매합니다\n",
      "Sentiment: LABEL_0, Score: 0.56\n",
      "\n",
      "Text: 좋은 가격에 잘 받았습니다\n",
      "Sentiment: LABEL_0, Score: 0.61\n",
      "\n",
      "Text: 좋은 상품을 많이 파세요재구매 합니다\n",
      "Sentiment: LABEL_0, Score: 0.64\n",
      "\n",
      "Text: 두번째 구매했습니다 변비가 심한편인데 요즘규칙적으로 하루 한번씩 볼일을 보는 것 같아요속이 편하고 좋아요\n",
      "Sentiment: LABEL_0, Score: 0.50\n",
      "\n",
      "Text: 딸아이가 다리가 너무 저리다고 해서 구입했어요 효과있다고 합니다 먹을때와 먹지 않을 때 다르다고 하네요 꾸준히 먹을게요\n",
      "Sentiment: LABEL_0, Score: 0.59\n",
      "\n",
      "Text: 좋아요 좋아요 좋아요\n",
      "Sentiment: LABEL_0, Score: 0.62\n",
      "\n",
      "Text: 캡슐이 은박지에 들어있어외출시 나누어 휴대하기 좋네요건강기능 식품으로 점차 신뢰가됩니다\n",
      "Sentiment: LABEL_0, Score: 0.54\n",
      "\n",
      "Text: 먹어보니 괜찮아서 더 구매할려구요\n",
      "Sentiment: LABEL_1, Score: 0.55\n",
      "\n",
      "Text: 좋은 상품 구매해서 좋았고 복용을 해 보니 피로감이 많이감소한것 같습니다 만족합니다 감사합니다\n",
      "Sentiment: LABEL_0, Score: 0.54\n",
      "\n",
      "Text: 믿을 수 있고 가격도 좋아요\n",
      "Sentiment: LABEL_0, Score: 0.60\n",
      "\n",
      "Text: 한알먹어보니 소변에서 별반응이없네요 비맥스 섭취하면 노란색이 학연하게 나타나던데 메가씨비타민씨 더먹어볼게요 하나먹어보고 효능이런걸 논한다는게 \n",
      "Sentiment: LABEL_1, Score: 0.61\n",
      "\n",
      "Text: 구매후기는 복용후 다시 자세히 작성하겠습니다\n",
      "Sentiment: LABEL_1, Score: 0.51\n",
      "\n",
      "Text: 바타민 메트르비와 부스터와 같이 복용 중인데 피로가 덜하고 힘이 생기는거 같아 먹고 잇어요\n",
      "Sentiment: LABEL_0, Score: 0.61\n",
      "\n",
      "Text: 잘 받았습니다\n",
      "Sentiment: LABEL_0, Score: 0.57\n",
      "\n",
      "Text: 갱년기 울 와이프 체육관 다니며 운동하고 다이어트 한다길래주문했어요 효과있기를\n",
      "Sentiment: LABEL_0, Score: 0.53\n",
      "\n",
      "Text: 운동하는데 쥐나는거 예방도 하구요\n",
      "Sentiment: LABEL_1, Score: 0.50\n",
      "\n",
      "Text: 저렴한 가격으로 열심히 먹고 있습니다 추후 혈당상태를 다시 남기도록 할게요\n",
      "Sentiment: LABEL_1, Score: 0.57\n",
      "\n",
      "Text: 싸게 사서 좋아요많이 파세요\n",
      "Sentiment: LABEL_0, Score: 0.52\n",
      "\n",
      "Text: 매우 흡족합니다\n",
      "Sentiment: LABEL_1, Score: 0.61\n",
      "\n",
      "Text: 효과 아주 바로 느껴집니다좋은 제품 저렴한 가격으로 구매했습니다감사합니다\n",
      "Sentiment: LABEL_1, Score: 0.58\n",
      "\n",
      "Text: 잘 먹고 있어요 한 2주 복용했는데 아직은 잘 모르겠어요 조금 더 먹어 봐야 알겠죠\n",
      "Sentiment: LABEL_0, Score: 0.51\n",
      "\n",
      "Text: 부모님이 좋은것 같다고 하셔서 재구매합니다 \n",
      "Sentiment: LABEL_0, Score: 0.52\n",
      "\n",
      "Text: 새주소로 변경했는데 여전히 예전 주소로 배달이 되네요 이대로는 주문할 수가 없어요 어케 해야하나요 정보수정을 다 했는데\n",
      "Sentiment: LABEL_1, Score: 0.57\n",
      "\n",
      "Text: 좋은제품 감사합니다\n",
      "Sentiment: LABEL_0, Score: 0.62\n",
      "\n",
      "Text: 이제시작했는데먹기도좋고간편하고실용적인데효과가있는것갔네요꾸준히먹고또나중에후기남기겠읍니다\n",
      "Sentiment: LABEL_0, Score: 0.56\n",
      "\n",
      "Text: 약국에서 권해서 먹던 건데여기가 더 저렴해서 구매했어요식사도 불규칙하고에어컨 틀어도 더운 곳에서 일하다보니저에게는 필수네요많이 파시고 번창하세요\n",
      "Sentiment: LABEL_1, Score: 0.52\n",
      "\n",
      "Text: 2통째 먹고 있어요작아서 더 먹기 좋아요\n",
      "Sentiment: LABEL_1, Score: 0.53\n",
      "\n",
      "Text: 좋은 제품 빠른 배송 너무 감사드립니다\n",
      "Sentiment: LABEL_0, Score: 0.55\n",
      "\n",
      "Text: 배송도 빠르고 너무 좋습니다\n",
      "Sentiment: LABEL_1, Score: 0.59\n",
      "\n",
      "Text: 면역에 좋다고해서 복용해보지만 아직잘 모르겠고 추가주문해서 장복할려고 합니다\n",
      "Sentiment: LABEL_1, Score: 0.53\n",
      "\n",
      "Text: 힘이생기는것 같은데 아직은 잘모르겠어요좋겠죠\n",
      "Sentiment: LABEL_1, Score: 0.55\n",
      "\n",
      "Text: 빠른배송개봉 후 냄새가 좀 나지만 먹을만 했음작은알이어서 먹기는 편함\n",
      "Sentiment: LABEL_1, Score: 0.57\n",
      "\n",
      "Text: 배송도 빠르게 해주시고 내용물도 만족스럽습니다\n",
      "Sentiment: LABEL_1, Score: 0.55\n",
      "\n",
      "Text: 착한가격에 구매해서 복용중인데 몇일밖에 안되서 아직은 잘 모르겠지만 아연이 좋다고하니 잘 복용하겠습니다\n",
      "Sentiment: LABEL_0, Score: 0.57\n",
      "\n",
      "Text: 잘 복용하고 있습니다\n",
      "Sentiment: LABEL_0, Score: 0.62\n",
      "\n",
      "Text: 아르기닌 참 좋은데 아르기닌 정말 좋은데 어떻게 표현할 방법이 없네\n",
      "Sentiment: LABEL_1, Score: 0.52\n",
      "\n",
      "Text: 잘 먹어보겠습니다 크기도 적당하고 목넘김 좋고뚜껑도 안전캡네요잘 먹고 건강해져 보겠습니다계속 재구매 예정입니다\n",
      "Sentiment: LABEL_0, Score: 0.61\n",
      "\n",
      "Text: 가성비 최고 만족합니다\n",
      "Sentiment: LABEL_0, Score: 0.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 감정 분석 수행 예시\n",
    "results = sentiment_analyzer(list)\n",
    "for text, result in zip(list, results):\n",
    "    print(f\"Text: {text}\\nSentiment: {result['label']}, Score: {result['score']:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = { \"text\": df_ex['ReviewText'],\"label\": [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]  # 1: 긍정, 0: 부정\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# 데이터프레임을 Hugging Face Dataset으로 변환\n",
    "dataset1 = Dataset.from_pandas(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = dataset1.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40/40 [00:00<00:00, 613.37 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 1248.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 데이터셋 토큰화\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeong\\BAF-24-2-medical\\myenv\\Lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 33%|███▎      | 5/15 [04:22<08:45, 52.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35699909925460815, 'eval_runtime': 10.9086, 'eval_samples_per_second': 0.917, 'eval_steps_per_second': 0.183, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 67%|██████▋   | 10/15 [06:06<02:00, 24.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32690343260765076, 'eval_runtime': 11.5545, 'eval_samples_per_second': 0.865, 'eval_steps_per_second': 0.173, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|██████████| 15/15 [07:46<00:00, 31.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3261677026748657, 'eval_runtime': 10.3163, 'eval_samples_per_second': 0.969, 'eval_steps_per_second': 0.194, 'epoch': 3.0}\n",
      "{'train_runtime': 466.0292, 'train_samples_per_second': 0.257, 'train_steps_per_second': 0.032, 'train_loss': 0.3167853037516276, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=0.3167853037516276, metrics={'train_runtime': 466.0292, 'train_samples_per_second': 0.257, 'train_steps_per_second': 0.032, 'train_loss': 0.3167853037516276, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3261677026748657, 'eval_runtime': 10.3838, 'eval_samples_per_second': 0.963, 'eval_steps_per_second': 0.193, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(eval_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_eval_batch_size=8,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "test_results= trainer.predict(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_results.predictions.argmax(axis=-1)  # 가장 높은 확률의 레이블 선택\n",
    "labels = test_results.label_ids  # 실제 레이블 (있다면)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 레이블: [1 1 1 1 1 1 1 1 1 1]\n",
      "실제 레이블: [1 1 1 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"예측 레이블:\", predictions)\n",
    "if labels is not None:\n",
    "    print(\"실제 레이블:\", labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
